{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLUTTER DEEP LEARNING COURSE\n",
    "#NEURAL NETWORK FOR FRUITS DETECTOR\n",
    "#MAKE SURE YOU HAVE DATASET IN THIS DIRECTORY\n",
    "#BY: Samuel Boylan-Sajous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './fruits-360/Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20479 images belonging to 131 classes.\n",
      "Found 2209 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.3,\n",
    "      height_shift_range=0.3,\n",
    "      horizontal_flip=True,\n",
    "      validation_split=0.1,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#     rescale=1./255, \n",
    "#     validation_split=0.05)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    subset='training')\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 224, 224, 3), (64, 131))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_generator:\n",
    "  break\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple Braeburn': 0, 'Apple Crimson Snow': 1, 'Apple Golden 1': 2, 'Apple Golden 2': 3, 'Apple Golden 3': 4, 'Apple Granny Smith': 5, 'Apple Pink Lady': 6, 'Apple Red 1': 7, 'Apple Red 2': 8, 'Apple Red 3': 9, 'Apple Red Delicious': 10, 'Apple Red Yellow 1': 11, 'Apple Red Yellow 2': 12, 'Apricot': 13, 'Avocado': 14, 'Avocado ripe': 15, 'Banana': 16, 'Banana Lady Finger': 17, 'Banana Red': 18, 'Beetroot': 19, 'Blueberry': 20, 'Cactus fruit': 21, 'Cantaloupe 1': 22, 'Cantaloupe 2': 23, 'Carambula': 24, 'Cauliflower': 25, 'Cherry 1': 26, 'Cherry 2': 27, 'Cherry Rainier': 28, 'Cherry Wax Black': 29, 'Cherry Wax Red': 30, 'Cherry Wax Yellow': 31, 'Chestnut': 32, 'Clementine': 33, 'Cocos': 34, 'Corn': 35, 'Corn Husk': 36, 'Cucumber Ripe': 37, 'Cucumber Ripe 2': 38, 'Dates': 39, 'Eggplant': 40, 'Fig': 41, 'Ginger Root': 42, 'Granadilla': 43, 'Grape Blue': 44, 'Grape Pink': 45, 'Grape White': 46, 'Grape White 2': 47, 'Grape White 3': 48, 'Grape White 4': 49, 'Grapefruit Pink': 50, 'Grapefruit White': 51, 'Guava': 52, 'Hazelnut': 53, 'Huckleberry': 54, 'Kaki': 55, 'Kiwi': 56, 'Kohlrabi': 57, 'Kumquats': 58, 'Lemon': 59, 'Lemon Meyer': 60, 'Limes': 61, 'Lychee': 62, 'Mandarine': 63, 'Mango': 64, 'Mango Red': 65, 'Mangostan': 66, 'Maracuja': 67, 'Melon Piel de Sapo': 68, 'Mulberry': 69, 'Nectarine': 70, 'Nectarine Flat': 71, 'Nut Forest': 72, 'Nut Pecan': 73, 'Onion Red': 74, 'Onion Red Peeled': 75, 'Onion White': 76, 'Orange': 77, 'Papaya': 78, 'Passion Fruit': 79, 'Peach': 80, 'Peach 2': 81, 'Peach Flat': 82, 'Pear': 83, 'Pear 2': 84, 'Pear Abate': 85, 'Pear Forelle': 86, 'Pear Kaiser': 87, 'Pear Monster': 88, 'Pear Red': 89, 'Pear Stone': 90, 'Pear Williams': 91, 'Pepino': 92, 'Pepper Green': 93, 'Pepper Orange': 94, 'Pepper Red': 95, 'Pepper Yellow': 96, 'Physalis': 97, 'Physalis with Husk': 98, 'Pineapple': 99, 'Pineapple Mini': 100, 'Pitahaya Red': 101, 'Plum': 102, 'Plum 2': 103, 'Plum 3': 104, 'Pomegranate': 105, 'Pomelo Sweetie': 106, 'Potato Red': 107, 'Potato Red Washed': 108, 'Potato Sweet': 109, 'Potato White': 110, 'Quince': 111, 'Rambutan': 112, 'Raspberry': 113, 'Redcurrant': 114, 'Salak': 115, 'Strawberry': 116, 'Strawberry Wedge': 117, 'Tamarillo': 118, 'Tangelo': 119, 'Tomato 1': 120, 'Tomato 2': 121, 'Tomato 3': 122, 'Tomato 4': 123, 'Tomato Cherry Red': 124, 'Tomato Heart': 125, 'Tomato Maroon': 126, 'Tomato Yellow': 127, 'Tomato not Ripened': 128, 'Walnut': 129, 'Watermelon': 130}\n"
     ]
    }
   ],
   "source": [
    "print (train_generator.class_indices)\n",
    "\n",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "\n",
    "with open('labels.txt', 'w') as f:\n",
    "  f.write(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False, \n",
    "                                              weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#       base_model,\n",
    "#   tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#   tf.keras.layers.Dense(131, activation='softmax')\n",
    "# ])\n",
    "\n",
    "#dl libraraies\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# specifically for cnn\n",
    "from keras.layers import Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "# modelling starts using a CNN.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    " \n",
    "\n",
    "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(131, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "#   tf.keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu'),\n",
    "#   tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#   tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'),\n",
    "#   tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "  tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "#   tf.keras.layers.Activation('relu')\n",
    "  tf.keras.layers.Dense(131, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             base_model,\n",
    "                             tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                             tf.keras.layers.Dropout(0.2),\n",
    "                             tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                             tf.keras.layers.Dense(131, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 39s 790ms/step - loss: 0.7621 - accuracy: 0.7903\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 48s 966ms/step - loss: 0.6163 - accuracy: 0.8247\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.5281 - accuracy: 0.8447\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.4377 - accuracy: 0.8759\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.4314 - accuracy: 0.8687\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 45s 900ms/step - loss: 0.3618 - accuracy: 0.8997\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.3275 - accuracy: 0.9013\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 44s 890ms/step - loss: 0.3003 - accuracy: 0.9144\n",
      "Epoch 9/10\n",
      "48/50 [===========================>..] - ETA: 1s - loss: 0.2743 - accuracy: 0.9189"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=50,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fruitsnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=tf.keras.models.load_model('fruitsnn.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model_dir = ''\n",
    "# tf.saved_model.save(model, saved_model_dir)\n",
    "\n",
    "# model.save('test.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
